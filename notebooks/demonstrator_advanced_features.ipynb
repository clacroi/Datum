{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datum demonstrator - basics\n",
    "\n",
    "**The aim of this notebook is to provide example code for using Datum dataset management library and tools.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datum.datasets.detection_dataset import Dataset\n",
    "from datum.formatters import DatumFormatter\n",
    "from datum.readers.voc_detection_reader import VocDetectionReader\n",
    "from datum.readers.coco_detection_reader import CocoDetectionReader\n",
    "from datum.readers import DatumReader\n",
    "from datum.transformers import EntryMapper, ObservableMapper, AttributesTransformer\n",
    "from datum.utils.datastore import list_existing_datastores, list_existing_datasets, register_dataset, load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced operations : combine multiple base Datum features to construct a new custom + filtered + composite dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5823/5823 [00:01<00:00, 3585.00it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 51987.30it/s]\n",
      "100%|██████████| 36781/36781 [00:00<00:00, 78514.65it/s]\n"
     ]
    }
   ],
   "source": [
    "# (1) Construct datasets to manipulate (15s)\n",
    "\n",
    "# Construct VOC train dataset\n",
    "root_dir = Path('/home/clacroix/databases/VOC2012/')\n",
    "train_images_list = Path('/home/clacroix/databases/VOC2012/ImageSets/Main/val.txt')\n",
    "reader = VocDetectionReader(root_dir, 'jpg', set_images_lists={'train': train_images_list})\n",
    "voc_train = Dataset()\n",
    "reader.feed(voc_train)\n",
    "\n",
    "to_int_xmin = ObservableMapper(['xmin'], ['xmin'], lambda x: int(round(x)))\n",
    "to_int_ymin = ObservableMapper(['ymin'], ['ymin'], lambda x: int(round(x)))\n",
    "to_int_xmax = ObservableMapper(['xmax'], ['xmax'], lambda x: int(round(x)))\n",
    "to_int_ymax = ObservableMapper(['ymax'], ['ymax'], lambda x: int(round(x)))\n",
    "voc_transformer = AttributesTransformer(observables_mappers=[to_int_xmin, to_int_ymin,\n",
    "                                                             to_int_xmax, to_int_ymax])\n",
    "voc_transformer.transform(voc_train)\n",
    "\n",
    "# Construct COCO train dataset (15 sec)\n",
    "root_dir = Path('/home/clacroix/workspace_corentin/databases/coco/')\n",
    "reader = CocoDetectionReader(root_dir, 'jpg')\n",
    "coco_val = Dataset()\n",
    "reader.feed(coco_val, sets=['val2017'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) Modify Coco dataset to align to VOC standards : use EntryMapper and ObservableMapper (30sec)\n",
    "\n",
    "# set attribute : 'train2017'-> 'train\"\n",
    "setmapper = EntryMapper(['set'], ['set'], lambda x: 'train' if x == 'train2017' else x)\n",
    "\n",
    "# Remap cat+cow+dog to animal and motorcycle to motorbike\n",
    "def remap(name):\n",
    "    if name in ['cat', 'cow', 'dog']:\n",
    "        return 'animal'\n",
    "    elif name == 'motorcycle':\n",
    "        return 'motorbike'\n",
    "    else:\n",
    "        return name\n",
    "nameremapper = ObservableMapper(['name'], ['name'], remap, obs_type='object')\n",
    "\n",
    "# Add 1 to xmin/ymin\n",
    "expand_xmin = ObservableMapper(['xmin'], ['xmin'], lambda x: x + 1)\n",
    "expand_ymin = ObservableMapper(['ymin'], ['ymin'], lambda x: x + 1)\n",
    "\n",
    "# apply all mappers\n",
    "coco_transformer = AttributesTransformer(entries_mappers=[setmapper],\n",
    "                                         observables_mappers=[nameremapper,\n",
    "                                                              to_int_xmin, to_int_ymin,\n",
    "                                                              to_int_xmax, to_int_ymax,\n",
    "                                                              expand_xmin, expand_ymin])\n",
    "coco_transformer.transform(coco_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34103/34103 [00:00<00:00, 340245.88it/s]\n",
      "100%|██████████| 519/519 [00:00<00:00, 172164.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# (3) Filter COCO objects based en their classes (5s)\n",
    "coco_obs = coco_val.observables_df\n",
    "\n",
    "# Filter out non VOC target classes\n",
    "target_classes = ['bicycle', 'boat', 'car', 'motorcycle']\n",
    "coco_obs['target'] = coco_obs['name'].apply(lambda x: True if x in target_classes else False)\n",
    "valid = coco_obs[coco_obs['target']]\n",
    "\n",
    "# Manually remove invalid observables from Datum dataset\n",
    "to_remove = coco_obs.drop(valid.index).index.values\n",
    "for obs_id in tqdm(to_remove):\n",
    "    coco_val.remove_observable(obs_id)\n",
    "\n",
    "# Remove images without GT objects\n",
    "coco_val.remove_entries_without_obs()\n",
    "\n",
    "# (4) Filter COCO images based on their characteristics (aspect ratio, dimension, #objects, etc)\n",
    "ar_min, ar_max = 1.3, 1.8\n",
    "min_height = 400\n",
    "max_n_objects = 15\n",
    "keep = 200\n",
    "\n",
    "# create objects DataFrame + columns aspect_ratio (ar), n_objects \n",
    "coco_images = coco_val.entries_df\n",
    "coco_images['ar'] = coco_images['width'] / coco_images['height']\n",
    "coco_images['n_objects'] = coco_images['obs_ids'].apply(lambda x: len(x))\n",
    "\n",
    "# filter based on aspect ratio\n",
    "valid = coco_images[(coco_images['ar'] > ar_min) & (coco_images['ar'] < ar_max)]\n",
    "\n",
    "# filter based on size\n",
    "valid = valid[valid['height'] > min_height]\n",
    "\n",
    "# filter based on #objects\n",
    "valid = valid[valid['n_objects'] < max_n_objects]\n",
    "\n",
    "# keep randomly only 1000 images\n",
    "np.random.seed(42)\n",
    "drop_indices = np.random.choice(valid.index, keep, replace=False)\n",
    "valid = valid.drop(drop_indices)\n",
    "\n",
    "# Manually remove invalid images from Datum dataset\n",
    "to_remove_idxs = coco_images.drop(valid.index).index.values\n",
    "for entry_id in tqdm(to_remove_idxs):\n",
    "    coco_val.remove_entry(int(entry_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040\n"
     ]
    }
   ],
   "source": [
    "# (5) Merge datasets and format result back to disk\n",
    "voc_coco250 = voc_train + coco_val\n",
    "print(len(voc_coco250))\n",
    "\n",
    "save_path = Path('/home/clacroix/tmp/VOC_COCO250/')\n",
    "formatter = DatumFormatter(save_path)\n",
    "formatter.format(voc_coco250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datum Datastore features\n",
    "\n",
    "Available functions :\n",
    "\n",
    "- list_existing_datastores() : display all existing datastores\n",
    "\n",
    "<pre> $list-existing-datastores </pre>\n",
    "\n",
    "- list_existing_datasets() :  display all existing datasets\n",
    "\n",
    "<pre> $list-existing-datasets </pre>\n",
    "\n",
    "- register_dataset() : register a dataset under Datum format @dataset_root_path to datastore with dataset_name\n",
    "\n",
    "<pre> $register-dataset dataset_root_path dataset_name datastore </pre>\n",
    "\n",
    "\n",
    "- load_dataset() : utility function for loading a dataset from a datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# DATASTORES\n",
      "## detection\n",
      "\n",
      "# DATASTORE detection (/home/clacroix/.local/lib/python3.6/site-packages/datum/datastores/detection.csv)\n",
      "## coco_val_reduced_datum (path : /home/corentin/tmp/datum_datum_format_test)\n",
      "\n",
      "\n",
      "\n",
      "# DATASTORE detection (/home/clacroix/.local/lib/python3.6/site-packages/datum/datastores/detection.csv)\n",
      "## coco_val_reduced_datum (path : /home/corentin/tmp/datum_datum_format_test)\n",
      "## voc_coco200 (path : /home/clacroix/tmp/VOC_COCO250)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (1) Show information about existing datastores : command-line of Python functions\n",
    "list_existing_datastores()\n",
    "list_existing_datasets()\n",
    "\n",
    "# (2) Add some datasets to a datastore : command-line or Python function register_dataset()\n",
    "register_dataset('/home/clacroix/tmp/VOC_COCO250/',\n",
    "                 'voc_coco200',\n",
    "                 'detection')\n",
    "list_existing_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry #458 : \n",
      "{'name': '2008_001765', 'filename': '2008_001765.jpg', 'dir': '/home/clacroix/databases/VOC2012/JPEGImages', 'width': 375, 'height': 500, 'set': 'train', 'idx': 458, 'obs_ids': [1202, 1203, 1204, 1205, 1206, 1207, 1208]}\n",
      "\n",
      "Entry #458 1st observable : \n",
      "{'type': 'object', 'name': 'person', 'xmin': 97, 'ymin': 151, 'xmax': 252, 'ymax': 500, 'idx': 1202, 'entry_id': 458}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (3) Load a dataset from a datastore\n",
    "voc_coco250_ah = load_dataset('voc_coco200')\n",
    "\n",
    "entry, observables = voc_coco250_ah[458]\n",
    "print('Entry #458 : \\n{}\\n'.format(entry))\n",
    "print('Entry #458 1st observable : \\n{}\\n'.format(observables[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
